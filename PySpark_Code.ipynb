{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b5cddd7-be3f-4228-a81d-27d95837a53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efe7f8db-e6ab-4d4e-a4df-9382520da1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/07/03 01:50:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Initialize spark session\n",
    "spark = SparkSession.builder \\\n",
    ".appName(\"Test\") \\\n",
    ".master(\"local[*]\") \\\n",
    ".enableHiveSupport() \\\n",
    ".getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5511e0d7-beb0-4fe6-995b-873965e6d441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# load data set\n",
    "df = spark.read.format(\"csv\").option(\"header\",True) \\\n",
    ".option(\"inferSchema\",True)\\\n",
    ".load(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ff0fb70-7cfe-4126-9bb2-7e4aca7d0ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- originName: string (nullable = true)\n",
      " |-- originTypeName: string (nullable = true)\n",
      " |-- destinationName: string (nullable = true)\n",
      " |-- destinationTypeName: string (nullable = true)\n",
      " |-- gradeName: string (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1133d07b-64b5-47c8-b4b8-7b1adc562a5c",
   "metadata": {},
   "source": [
    "### 1. What are the top 5 destinations for oil produced in Albania?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "091e4be1-789f-4aee-8832-d2e7bc8a4840",
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_albania_destinations = df.filter(upper(col(\"originName\"))=='ALBANIA') \\\n",
    ".groupBy(\"destinationName\") \\\n",
    ".agg(sum(\"quantity\").alias(\"Total_Qty\")) \\\n",
    ".orderBy(\"Total_Qty\",ascending=False).limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8fab0ab-5a71-495e-a4f8-6486db6c3fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:==============>                                            (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|     destinationName|Total_Qty|\n",
      "+--------------------+---------+\n",
      "|  PADD1 (East Coast)|     9926|\n",
      "|          New Jersey|     9926|\n",
      "|       United States|     4963|\n",
      "|       Paulsboro, NJ|     4963|\n",
      "|AXEON SPECIALTY P...|     4963|\n",
      "+--------------------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "top5_albania_destinations.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefc10f9-984f-4649-aea0-15f49cf6fa1b",
   "metadata": {},
   "source": [
    "\n",
    "### 2. For UK, which destinations have a total quantity greater than 100,000?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98228133-f1aa-447e-8ed4-3a035b8dce4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_destinations = df.filter(col(\"originName\")=='United Kingdom') \\\n",
    ".groupBy(\"destinationName\") \\\n",
    ".agg(sum(\"quantity\").alias(\"Total_Qty\")) \\\n",
    ".filter(col(\"Total_Qty\") > 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fded50d-cffb-4034-9e49-b37cc70fefea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:====================================>                      (5 + 3) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------+\n",
      "|   destinationName|Total_Qty|\n",
      "+------------------+---------+\n",
      "|             Texas|   137125|\n",
      "|     United States|   233095|\n",
      "|PADD3 (Gulf Coast)|   354908|\n",
      "|         Louisiana|   112342|\n",
      "|       Mississippi|   101885|\n",
      "+------------------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "uk_destinations.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3e70d1-fe32-43ac-97ca-bbdd91a30e10",
   "metadata": {},
   "source": [
    "### 3) What was the most exported grade for each year and origin?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78d19fa9-f0dc-420d-8ff1-0d065c296145",
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_grades = df.groupBy(\"year\",\"originName\",\"gradeName\") \\\n",
    ".agg(sum(\"quantity\").alias(\"Total_Qty\")) \\\n",
    ".withColumn(\"rn\",dense_rank().over(Window.partitionBy(\"year\",\"originName\").orderBy(col(\"Total_Qty\").desc()))) \\\n",
    ".filter(col(\"rn\")==1) \\\n",
    ".drop(\"rn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bf6c0f6-e81f-4c72-ae1c-e6b8ee779565",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:=======>                                                   (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+-----------+---------+\n",
      "|year|       originName|  gradeName|Total_Qty|\n",
      "+----+-----------------+-----------+---------+\n",
      "|2009|           Africa|Light Sweet|  2559851|\n",
      "|2009|          Algeria|Light Sweet|   698243|\n",
      "|2009|           Angola|     Medium|   840693|\n",
      "|2009|        Argentina|Heavy Sweet|   115633|\n",
      "|2009|     Asia-Pacific|Light Sweet|   129815|\n",
      "|2009|        Australia|Light Sweet|    18074|\n",
      "|2009|       Azerbaijan|Light Sweet|   223433|\n",
      "|2009|           Belize| Light Sour|     4277|\n",
      "|2009|          Bolivia|Light Sweet|     9611|\n",
      "|2009|           Brazil| Heavy Sour|   638687|\n",
      "|2009|         Cameroon|Heavy Sweet|    81445|\n",
      "|2009|           Canada| Heavy Sour|  2716028|\n",
      "|2009|  Canada (Region)| Heavy Sour|  2716028|\n",
      "|2009|             Chad|Heavy Sweet|   165186|\n",
      "|2009|            China|Heavy Sweet|    13734|\n",
      "|2009|         Colombia| Heavy Sour|   510496|\n",
      "|2009|Congo-Brazzaville|Light Sweet|   146342|\n",
      "|2009|   Congo-Kinshasa|     Medium|    23884|\n",
      "|2009|    Cote d'Ivoire|     Medium|     2429|\n",
      "|2009|          Ecuador| Heavy Sour|   442211|\n",
      "+----+-----------------+-----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "exported_grades.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783f67a3-43cd-45c7-96b7-f924bd6d55f2",
   "metadata": {},
   "source": [
    "### BONUS Question: In order to save output from Question.1 dataframe to Inceberg file format below code can be used:\n",
    "\n",
    "top5_albania_destinations.write \\\n",
    "    .format(\"iceberg\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(\"spark_catalog.default.top5_albania_destinations\")\n",
    "\n",
    "\n",
    "## Additionally, while initializing the Spark Session few additional configurations would need to be added!!\n",
    "\n",
    "\n",
    ".config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    ".config(\"spark.sql.catalog.spark_catalog\", \"org.apache.iceberg.spark.SparkSessionCatalog\") \\\n",
    ".config(\"spark.sql.catalog.spark_catalog.type\", \"hive\") \n",
    "\n",
    "\n",
    "## However, while running the PySpark code, it's throwing errors for Python version and spark catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd1f5ee7-f8b0-4ffc-a268-6e7160bf96c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
